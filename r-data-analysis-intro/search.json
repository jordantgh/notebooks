[
  {
    "objectID": "basic-data-analysis.html",
    "href": "basic-data-analysis.html",
    "title": "R Basics: Data Analysis",
    "section": "",
    "text": "The first step when doing any kind of data analysis with code is getting the data in and cleaning it up. Compared to using Excel, GraphPad, etc, this is arguably the point of highest relative friction when working with code. Programming languages prefer data in a neat and tidy tabular format, and usually it isn’t like that to begin with, so we have to do some cleaning and reshaping.\nThis takes some work, but depending on the purposes, is often worth it in the end.\n\nlibrary(readxl) # A useful library for reading Excel files\n\nalamar_raw_plate &lt;- read_excel(\n  \"jt58 etoposide kill curve 24h post eto wt vs 3ko13 3ko17 alamar.xlsx\",\n  range = \"B15:M22\", # For plate data, know where your plate reader puts it!\n  col_names = FALSE\n)\n\n# Or, since we only use read_excel, we could just write `readxl::read_excel`\n# (This is better practice than loading the entire library for one function)\n\nalamar_raw &lt;- alamar_raw_plate[1:7, 2:10] # Trim away empty wells\n# Or, equivalently: alamar_raw &lt;- alamar_raw_plate[-8, 2:10]\n\ncolumns &lt;- c(\n  \"WT_Par_1\", \"WT_Par_2\", \"WT_Par_3\",\n  \"M3KO_13_1\", \"M3KO_13_2\", \"M3KO_13_3\",\n  \"M3KO_17_1\", \"M3KO_17_2\", \"M3KO_17_3\"\n)\n\ncolnames(alamar_raw) &lt;- columns\n\n# Get and subtract the control wells\n\nbackground &lt;- as.numeric(alamar_raw[1,]) # `mean()` won't work on a data frame\navg_background &lt;- mean(background)\n\nalamar_corrected &lt;- alamar_raw - avg_background # Subtracts from each well\nalamar_corrected &lt;- alamar_corrected[-1,] # Remove the control wells\n\n# Set the concentrations and add to the table\n\netoposide_concs &lt;- rev(c(0, 10^seq(0, 2, by = 0.5)))\nalamar_corrected$conc &lt;- etoposide_concs\n\n# Print out a preview of the data frame\nknitr::kable(alamar_corrected) # kable() gives us the table in a pretty format\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWT_Par_1\nWT_Par_2\nWT_Par_3\nM3KO_13_1\nM3KO_13_2\nM3KO_13_3\nM3KO_17_1\nM3KO_17_2\nM3KO_17_3\nconc\n\n\n\n\n2\n14115.11\n14049.11\n12654.11\n16593.11\n14042.11\n12500.11\n16366.11\n17546.11\n17689.11\n100.000000\n\n\n3\n20673.11\n21094.11\n19703.11\n20867.11\n20014.11\n19244.11\n22239.11\n23283.11\n21522.11\n31.622777\n\n\n4\n24720.11\n23917.11\n23770.11\n26173.11\n24603.11\n25396.11\n27008.11\n27124.11\n27459.11\n10.000000\n\n\n5\n30768.11\n28518.11\n28870.11\n35366.11\n32207.11\n31524.11\n34026.11\n34491.11\n33068.11\n3.162278\n\n\n6\n40312.11\n37844.11\n38779.11\n43027.11\n43023.11\n42544.11\n43659.11\n44205.11\n42573.11\n1.000000\n\n\n7\n42933.11\n43014.11\n42832.11\n48129.11\n47546.11\n47462.11\n50355.11\n47030.11\n49155.11\n0.000000"
  },
  {
    "objectID": "basic-data-analysis.html#data-ingestion",
    "href": "basic-data-analysis.html#data-ingestion",
    "title": "R Basics: Data Analysis",
    "section": "",
    "text": "The first step when doing any kind of data analysis with code is getting the data in and cleaning it up. Compared to using Excel, GraphPad, etc, this is arguably the point of highest relative friction when working with code. Programming languages prefer data in a neat and tidy tabular format, and usually it isn’t like that to begin with, so we have to do some cleaning and reshaping.\nThis takes some work, but depending on the purposes, is often worth it in the end.\n\nlibrary(readxl) # A useful library for reading Excel files\n\nalamar_raw_plate &lt;- read_excel(\n  \"jt58 etoposide kill curve 24h post eto wt vs 3ko13 3ko17 alamar.xlsx\",\n  range = \"B15:M22\", # For plate data, know where your plate reader puts it!\n  col_names = FALSE\n)\n\n# Or, since we only use read_excel, we could just write `readxl::read_excel`\n# (This is better practice than loading the entire library for one function)\n\nalamar_raw &lt;- alamar_raw_plate[1:7, 2:10] # Trim away empty wells\n# Or, equivalently: alamar_raw &lt;- alamar_raw_plate[-8, 2:10]\n\ncolumns &lt;- c(\n  \"WT_Par_1\", \"WT_Par_2\", \"WT_Par_3\",\n  \"M3KO_13_1\", \"M3KO_13_2\", \"M3KO_13_3\",\n  \"M3KO_17_1\", \"M3KO_17_2\", \"M3KO_17_3\"\n)\n\ncolnames(alamar_raw) &lt;- columns\n\n# Get and subtract the control wells\n\nbackground &lt;- as.numeric(alamar_raw[1,]) # `mean()` won't work on a data frame\navg_background &lt;- mean(background)\n\nalamar_corrected &lt;- alamar_raw - avg_background # Subtracts from each well\nalamar_corrected &lt;- alamar_corrected[-1,] # Remove the control wells\n\n# Set the concentrations and add to the table\n\netoposide_concs &lt;- rev(c(0, 10^seq(0, 2, by = 0.5)))\nalamar_corrected$conc &lt;- etoposide_concs\n\n# Print out a preview of the data frame\nknitr::kable(alamar_corrected) # kable() gives us the table in a pretty format\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWT_Par_1\nWT_Par_2\nWT_Par_3\nM3KO_13_1\nM3KO_13_2\nM3KO_13_3\nM3KO_17_1\nM3KO_17_2\nM3KO_17_3\nconc\n\n\n\n\n2\n14115.11\n14049.11\n12654.11\n16593.11\n14042.11\n12500.11\n16366.11\n17546.11\n17689.11\n100.000000\n\n\n3\n20673.11\n21094.11\n19703.11\n20867.11\n20014.11\n19244.11\n22239.11\n23283.11\n21522.11\n31.622777\n\n\n4\n24720.11\n23917.11\n23770.11\n26173.11\n24603.11\n25396.11\n27008.11\n27124.11\n27459.11\n10.000000\n\n\n5\n30768.11\n28518.11\n28870.11\n35366.11\n32207.11\n31524.11\n34026.11\n34491.11\n33068.11\n3.162278\n\n\n6\n40312.11\n37844.11\n38779.11\n43027.11\n43023.11\n42544.11\n43659.11\n44205.11\n42573.11\n1.000000\n\n\n7\n42933.11\n43014.11\n42832.11\n48129.11\n47546.11\n47462.11\n50355.11\n47030.11\n49155.11\n0.000000"
  },
  {
    "objectID": "basic-data-analysis.html#reshaping-the-data",
    "href": "basic-data-analysis.html#reshaping-the-data",
    "title": "R Basics: Data Analysis",
    "section": "Reshaping the data",
    "text": "Reshaping the data\nThe data is still not in the format modelling and plotting functions expect.\nThe key to tidy data is simple enough: one column per variable. This is the format that most data analysis software expects or tries to force data to be in.\nThe “why” of tidy data is discussed at length by Hadley Wickham, chief scientist at Posit (who make RStudio). If interested, take a gander: https://vita.had.co.nz/papers/tidy-data.pdf\nFor a more practical guide, you can look here: https://r4ds.had.co.nz/tidy-data.html\nIn this code, I use the tidyr library, and there is a very helpful cheetsheet that I basically always check when I need to use it, if you just want a quick answer on how to do a given thing: https://rstudio.github.io/cheatsheets/tidyr.pdf\nThe pivot_longer function here lets us turn the unique columns for each genotype and replicate in the above into a simpler data frame with one genotype column and one replicate column. In practise, we don’t need the replicate column but I’ve included it here just to be explicit.\n\nalamar &lt;- tidyr::pivot_longer(\n  data = alamar_corrected,\n  cols = -conc, # all columns except `conc`\n  names_sep = \"_\",\n  names_to = c(\"genotype\", \"clone\", \"replicate\"),\n  values_to = \"corrected_absorbance\"\n)\n\nknitr::kable(head(alamar, 10)) # Just show the first 10 rows\n\n\n\n\nconc\ngenotype\nclone\nreplicate\ncorrected_absorbance\n\n\n\n\n100.00000\nWT\nPar\n1\n14115.11\n\n\n100.00000\nWT\nPar\n2\n14049.11\n\n\n100.00000\nWT\nPar\n3\n12654.11\n\n\n100.00000\nM3KO\n13\n1\n16593.11\n\n\n100.00000\nM3KO\n13\n2\n14042.11\n\n\n100.00000\nM3KO\n13\n3\n12500.11\n\n\n100.00000\nM3KO\n17\n1\n16366.11\n\n\n100.00000\nM3KO\n17\n2\n17546.11\n\n\n100.00000\nM3KO\n17\n3\n17689.11\n\n\n31.62278\nWT\nPar\n1\n20673.11"
  },
  {
    "objectID": "basic-data-analysis.html#modelling-and-plotting",
    "href": "basic-data-analysis.html#modelling-and-plotting",
    "title": "R Basics: Data Analysis",
    "section": "Modelling and plotting",
    "text": "Modelling and plotting\nNow that we have the data in the right format, we can use R’s tools for making statistical models and plotting them. Since we have dose-response data, we can use the drc package. Normally, dose-response curves in biology are not linear, but S-shaped, and we typically model S-shaped data with so called “logistic” models, usually the “4-parameter” logistic model (the 4 parameters are: minimum, maximum, slope steepness, and inflection point). drc gives us easy access to a whole family of dose response models, so we don’t really have to get into the maths.\n\nlibrary(drc) # Both drm & LL.4() are from this library, so OK to import it all\n\ndose_response_model &lt;- drm(\n  corrected_absorbance ~ conc, # Model absorbance as a function of concentration\n  fct = LL.4(), # This says to use the 4-parameter logistic model\n  curveid = genotype, # This says: do a separate model/curve for each genotype\n  data = alamar # specifies the dataframe\n)\n\nec50 &lt;- ED(dose_response_model, 50) # (We can choose any %, not just 50%)\n\n\nEstimated effective doses\n\n          Estimate Std. Error\ne:M3KO:50  4.87290    0.71092\ne:WT:50    6.13149    2.08416\n\nplot(dose_response_model)\nabline(v=c(ec50[1],ec50[2]), col=c(\"blue\", \"red\"), lty=c(1,3))"
  },
  {
    "objectID": "basic-data-analysis.html#making-the-plot-prettier",
    "href": "basic-data-analysis.html#making-the-plot-prettier",
    "title": "R Basics: Data Analysis",
    "section": "Making the plot prettier",
    "text": "Making the plot prettier\nThe base R plots are fine for a quick and dirty inspection, but depending on what you want to show, there are far more powerful libraries.\n\nlibrary(ggplot2)\nlibrary(ggprism)\n\n# First set the genotype to a factor so we can control the order (for legends)\n# (ggplot will convert it under the hood, and the default order is alphabetical)\nalamar$genotype &lt;- factor(alamar$genotype, levels = c(\"WT\", \"M3KO\"))\n\n# Then we make the labels useful for plotting\nlevels(alamar$genotype) &lt;- c(\"Wild-type\", \"IFITM3 KO\")\n\nmax_y &lt;- max(alamar$corrected_absorbance)\n\nplot &lt;- ggplot(\n  alamar,\n  aes(x = conc, y = corrected_absorbance, color = genotype, fill = genotype)\n)\n\nplot &lt;- plot +\n  geom_line(\n    stat = \"smooth\",\n    method = drm,\n    method.args = list(fct = LL.4()),\n    linewidth = 2,\n    se = FALSE\n  ) +\n  geom_point(\n    color = \"black\",\n    pch = 21,\n    size = 3,\n    alpha = 0.8,\n    stroke = 1.2\n  ) +\n  scale_color_manual(values = c(\"#5278ec\", \"#bb0c40\")) +\n  scale_fill_manual(values = c(\"#5278ec\", \"#bb0c40\")) +\n  theme_prism(base_size = 14) +\n  scale_y_continuous(limits = c(NA, max_y * 1.1)) +\n  scale_x_continuous(\n    trans = scales::pseudo_log_trans(0.1),\n    labels = scales::label_number(drop0trailing = TRUE),\n    breaks = c(0, 0.3, 1, 3, 10, 30, 100)\n  ) +\n  labs(x = \"Etoposide (µM)\", y = \"Abs (450)\")\n\n# add the EC50 lines\nplot &lt;- plot +\n  geom_vline(\n    xintercept = ec50[1],\n    color = \"#5278ec\",\n    linewidth = 1.1,\n    linetype = 2\n  ) +\n  geom_vline(\n    xintercept = ec50[2],\n    color = \"#bb0c40\",\n    linewidth = 1.1,\n    linetype = 3\n  )\n\nplot$theme[c(\"legend.text.align\", \"legend.title.align\")] &lt;- NULL\n\nplot"
  }
]